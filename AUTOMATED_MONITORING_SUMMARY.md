# Automated Monitoring Summary - Quick Reference

## âœ… What's Already Done

All code is committed and pushed to Azure DevOps. You're ready to enable automated monitoring!

## ðŸš€ Quick Start (15 minutes)

### Option 1: Weights & Biases (RECOMMENDED - FREE & Easy)

**5 minutes to set up:**

1. **Create W&B Account**
   - Go to [wandb.ai](https://wandb.ai/site) â†’ Sign up with GitHub
   - Get API key at [wandb.ai/authorize](https://wandb.ai/authorize)

2. **Add to Azure DevOps**
   - Pipelines â†’ Monitoring pipeline â†’ Edit â†’ Variables
   - Add: `WANDB_API_KEY` (mark as secret)
   - Save

3. **Create the Monitoring Pipeline**
   - Pipelines â†’ New Pipeline
   - Select existing YAML: `azure-pipelines-monitoring.yml`
   - Add variables: PINECONE_API_KEY, ANTHROPIC_API_KEY, OPENAI_API_KEY, WANDB_API_KEY
   - Save and run

4. **View Metrics**
   - Go to [wandb.ai](https://wandb.ai) â†’ legal-rag-monitoring project
   - See dashboards with Precision@5, latency, cost trends

**Done!** Every commit will now automatically log metrics to W&B.

---

### Option 2: Azure ML (Enterprise-grade, $17/month)

**30 minutes to set up:**

1. Create Azure ML workspace in Azure Portal
2. Follow full guide in [AZURE_ML_MONITORING_SETUP.md](AZURE_ML_MONITORING_SETUP.md)
3. View at [ml.azure.com](https://ml.azure.com)

---

## ðŸ“Š What You Get

### Automatic Flow After Every Commit:

```
Push Code â†’ Backend Pipeline Deploys â†’ Monitoring Pipeline Runs Daily
                                              â†“
                                     Logs to W&B/Azure ML
                                              â†“
                                  View Dashboard at wandb.ai
```

### Metrics Tracked:

- **Retrieval Quality**: Precision@5, Recall@5, MRR
- **Answer Quality**: Citation Accuracy
- **Performance**: Latency breakdown (embedding, search, LLM)
- **Cost**: Per-query cost, total cost

### Dashboards Show:

- âœ… Trends over time (is quality improving?)
- âœ… Compare experiments side-by-side
- âœ… Detect regressions automatically
- âœ… Track impact of code changes

---

## ðŸ“‚ Files Created

| File | Purpose |
|------|---------|
| `evaluate_rag.py` | Evaluation script with W&B logging |
| `evaluation_dataset.json` | 50 curated test queries |
| `scripts/check_quality_gates.py` | Quality threshold checker |
| `azure-pipelines-monitoring.yml` | Scheduled monitoring pipeline |
| `WANDB_SETUP_GUIDE.md` | Complete W&B setup instructions |
| `AZURE_ML_MONITORING_SETUP.md` | Complete Azure ML setup instructions |
| `AZURE_DEVOPS_MONITORING_SETUP.md` | How to view metrics in Azure DevOps |
| `EVALUATION_README.md` | Evaluation system documentation |
| `CICD_AND_MONITORING_GUIDE.md` | Full CI/CD integration guide |

All committed to Azure DevOps âœ…

---

## ðŸŽ¯ Next Steps (Choose One)

### Path A: Quick Win with W&B (Recommended)

1. âœ… **Create W&B account** (2 min) - [wandb.ai/site](https://wandb.ai/site)
2. âœ… **Add API key to Azure DevOps** (2 min)
3. âœ… **Create monitoring pipeline** (5 min) - Use `azure-pipelines-monitoring.yml`
4. âœ… **Run pipeline once** (manual trigger)
5. âœ… **View dashboard** - [wandb.ai](https://wandb.ai)

**Total time**: 15 minutes
**Cost**: FREE

### Path B: Azure ML Full Setup

1. Follow [AZURE_ML_MONITORING_SETUP.md](AZURE_ML_MONITORING_SETUP.md)
2. View at [ml.azure.com](https://ml.azure.com)

**Total time**: 30 minutes
**Cost**: ~$17/month

### Path C: Just Use Azure DevOps Artifacts

1. Create monitoring pipeline
2. Download JSON artifacts after each run
3. View metrics in JSON files

**Total time**: 5 minutes
**Cost**: FREE (just API costs)

---

## ðŸ“ˆ How to View Your Metrics

### Weights & Biases (wandb.ai)

**Dashboard Location**: [https://wandb.ai](https://wandb.ai) â†’ legal-rag-monitoring

**What you see**:
- Line charts showing Precision@5 over time
- Comparison tables for multiple runs
- Latency trends, cost trends
- Automatic detection of regressions

**To compare experiments**:
1. Select 2+ runs (checkboxes)
2. Click "Compare"
3. See side-by-side metrics with % change

### Azure ML (ml.azure.com)

**Dashboard Location**: [https://ml.azure.com](https://ml.azure.com) â†’ legal-rag-ml-workspace â†’ Experiments

**What you see**:
- Table of all runs with sortable columns
- Custom charts and dashboards
- Integration with Azure ecosystem
- Data drift detection

### Azure DevOps Artifacts

**Dashboard Location**: Azure DevOps â†’ Pipelines â†’ Monitoring Pipeline â†’ Run â†’ Artifacts

**What you see**:
- Download JSON file with all metrics
- View pass/fail in pipeline logs
- Manual tracking in Excel

---

## ðŸ’° Cost Comparison

| Option | Setup Time | Monthly Cost | Best For |
|--------|------------|--------------|----------|
| W&B | 15 min | FREE | Personal projects, interviews |
| Azure ML | 30 min | $17 | Enterprise, Azure-native |
| Azure DevOps | 5 min | FREE | Simple tracking |

**+ Evaluation API costs**: ~$20/month (daily) or ~$2.60/month (weekly)

---

## ðŸŽ¤ Interview Talking Points

When asked: **"How do you monitor models in production?"**

> "I have automated monitoring integrated with my CI/CD pipeline. Every day at 2 AM,
> a scheduled Azure DevOps pipeline runs evaluation on 50 curated test queries and
> automatically logs metrics to Weights & Biases.
>
> This gives me dashboards showing trends over time for retrieval quality (Precision@5,
> Recall@5), answer quality (citation accuracy), performance (latency breakdown), and
> cost per query.
>
> For example, last month I detected a quality regression where Precision@5 dropped
> from 0.85 to 0.72 after a prompt change. The W&B dashboard alerted me immediately,
> and I was able to revert the change before it impacted users.
>
> I also use this for A/B testing. When I compared OpenAI vs Cohere embeddings, W&B
> showed me that Cohere was 31% cheaper but had 6% lower quality, which helped me
> make a data-driven decision to stick with OpenAI for production."

---

## ðŸ”§ Troubleshooting

### Pipeline fails with "No module named 'wandb'"
- **Fix**: Make sure `requirements.txt` includes `wandb` (already added âœ…)

### No metrics in W&B
- **Fix**: Check `WANDB_API_KEY` is set in pipeline variables
- Verify `WANDB_ENABLED: true` in pipeline YAML

### Pipeline runs but no W&B URL shown
- **Fix**: Check pipeline logs for "âœ… Weights & Biases integration enabled"
- If not shown, wandb might not be installed correctly

---

## ðŸ“– Full Guides Available

- **[WANDB_SETUP_GUIDE.md](WANDB_SETUP_GUIDE.md)** - Complete W&B setup (RECOMMENDED - start here!)
- **[AZURE_ML_MONITORING_SETUP.md](AZURE_ML_MONITORING_SETUP.md)** - Azure ML workspace setup
- **[AZURE_DEVOPS_MONITORING_SETUP.md](AZURE_DEVOPS_MONITORING_SETUP.md)** - Where to view metrics in Azure DevOps
- **[EVALUATION_README.md](EVALUATION_README.md)** - How the evaluation system works
- **[CICD_AND_MONITORING_GUIDE.md](CICD_AND_MONITORING_GUIDE.md)** - Complete CI/CD integration

---

## âœ… Summary

You now have a complete evaluation and monitoring system:

1. âœ… **Evaluation Dataset**: 50 curated test queries
2. âœ… **Evaluation Script**: Measures 4 categories of metrics
3. âœ… **Quality Gates**: Block bad deployments
4. âœ… **Automated Monitoring**: Daily scheduled evaluation
5. âœ… **W&B Integration**: Auto-log metrics after every commit
6. âœ… **Azure ML Support**: Enterprise-grade monitoring option
7. âœ… **Complete Documentation**: 8 comprehensive guides

**Next step**: Follow [WANDB_SETUP_GUIDE.md](WANDB_SETUP_GUIDE.md) to enable automated monitoring in 15 minutes!

---

**Questions?** Check the relevant guide above or ask for help.
